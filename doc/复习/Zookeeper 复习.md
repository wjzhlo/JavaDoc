# Zookeeper 复习

## Zookeeper 基础

### 什么是 Zookeeper

`Zookeeper 是一个分布式服务管理框架，可以作为分布式系统的注册中心，同时可以支持全局唯一ID、配置中心、分布式锁等多种功能的实现。内部是通过观察者模式`



### zk 能做什么

- **作为微服务的注册中心**
  - 通过观察者模式实现服务订阅和服务通知，当一个客户端连接到 zk 上时，zk 会为其生成对应的临时节点，并存储这个节点的网络地址、状态、订阅内容等，并与这些客户端维持长连接，当服务提供者信息发生变化时，可以通过长连接通知订阅了这些服务的客户端
- **作为配置中心**
  - 实际也是依赖观察者模式，即将配置信息存储在 zk 的节点上，客户端可以订阅 zk 上这些节点的变化事件，当事件变化时重新从服务器获取并加载
- **全局唯一 ID**
  - 全局唯一ID 是通过 zk 的临时有序节点实现的，zk 会为其维护顺序并保证自增，因此只需要在生成全局唯一ID时在zk上创建一个临时有序节点，并以节点名称为id即可
  - 但实际上由于 zk 保证了一致性，因此存在性能瓶颈，一般使用 redis 也可以很好地实现全局唯一id
  - 常见实现全局唯一ID的方式有雪花算法、zk、redis
- **分布式锁**
  - 由于 zk 的一致性，因此在分布式环境下可以实现分布式锁



### ZK 的结构

- zk 是以多叉树树形存储数据的，树中的节点叫做 znode
- 每个子节点的路径都依赖于父节点，因此每个子节点的路径都是唯一的，可以通过这个路径来找到这个节点
- znode 中维护着数据、ACL、时间戳等数据，我们可以将数据存储在 znode 中，通过 znode 节点的路径来处理和找到它



### ZK 的节点类型

按生命周期分为持久化节点和临时节点，临时节点会会话结束后自动删除，这也是 zk 作为注册中心的关键

- 永久有序节点

- 永久无序节点
- 临时有序节点
- 临时无序节点



### ZK 的 ACL 控制

`ACL 就是访问权限控制，可以为某个 znode 节点设置授权模式、授权对象和权限，一般项目中不怎么用`



## Zookeeper  相关机制

### watcher 机制

要说 watcher 机制时，应该分为三个部分说明：

- watcher 机制是什么，做了什么
- watcher 的特性
- watcher 内部结构
- watcher 原理
- watcher 如何使用
- watcher 的限制 => 只能使用一次
  - 为什么这样设计 => 避免某些节点频繁更新，服务端不断通知客户端，对客户端造成压力
  - 如何解决 => 必须重复订阅
- 如何解决 watcher 机制的问题？ =>  使用 curator 框架



#### watcher 是什么，做了什么

`watcher 机制是 zk 提供的一种发布/订阅功能，zk 客户端能够通过 watcher 机制订阅指定的 znode 节点，当这个节点或其子节点发生变化时会主动异步通知客户端，避免客户端注册 watcher 后轮询阻塞，底层是使用 NIO 实现`



#### watcher 特性

- **一次性**
  - watcher 是一次性的，一旦触发就会被移除，想使用必须重新注册
- **客户端顺序回调**
  - 在客户端中是使用串行化来处理 watcher 的，即如果存在多个 watcher，只会按事件发生时间依次执行，只有一个回调完成了，才会执行下一个回调
- **轻量级**
  - WatchEvent 上只包含了通知状态、事件类型以及节点路径，具体内容要客户端自己去获取
- **实效性**
  - watcher 只有 session 彻底失效才会无效，如果 session 快速重连成功，则 watcher 依然存在



#### watcher 的内部结构

**组成：**

- zk 服务端
- zk 客户端
- 客户端 watch 管理器

**流程：**

- 客户端先将 watcher 注册到服务端，同时将这个 watcher 保存到 watch 管理器中
- 当 zk 服务端监听到数据发生变化时，服务端会主动通知客户端
- 客户端 watch 管理器会触发对应的 watcher 来处理，处理完就删除掉这个 watcher



#### 为什么 watcher 只能使用一次

这是由于 zk 为了避免节点频繁变化导致服务端一直通知客户端，造成客户端的服务压力。如果要重复订阅，可以在回调中重新订阅一次。在 curator 框架中已经帮我处理了



#### watcher 原理

https://blog.csdn.net/l6108003/article/details/97172579

https://www.cnblogs.com/lanqiu5ge/p/9405601.html#_label0   ====>   第八点

**zk 客户端处理流程：**

- 初始化时，zk 会先注册一个注册监听器，用于监听 zk 服务器是否连接成功
- zk 服务器连接成功后，注册监听器会被移除。zk 客户端会先获取 zoo.cfg 的配置，支持 socket 方式或 netty 方式连接，默认 socket 方式
- 支持的 watcher 方法有 exist/getData/getChildren，在创建 watcher 的方法中，会构造 Header、请求体等数据对象，并打包发送给 zk 服务端
- zk 客户端中有两个队列，分别为 outgoingQueue 和 pendingQueue，当调用了watcher 提供的三个方法后，会将构造出来的包放到 outgoingQueue 中，等待线程消费
- SendThread 线程会将包从 outgoingQueue 中取出，并发送到 zk 服务器，发送成功后会将这个包扔到 pendingQueue 中
- 当服务器有响应数据时，SendThread 会读取从 zk 服务器返回的数据，并将包从 pendingQueue 中取出，并调用回调方法



**zk 服务端处理流程：**

- zk 服务器中存储着两个 HashMap，一个是节点名称与监听器的HashSet 的接收到 watcher 请求后，xxxx





### ZAB 协议

说 ZAB 协议时，也要分析从哪些角度说明：

- zab 协议是什么，租了什么
- zab 协议的原理
- paxos 算法



#### zab 协议是什么

##### 概念

zab 是 zookeeper 专门设计的一种支持崩溃恢复、主从数据同步的原子广播协议，通过二阶段提交的方式来保证集群中分布式数据的一致性



##### 角色

角色分为领导者、追随者、观察者三种

- 领导者负责投票的发起和决议，并更新系统状态
- 追随者用于接收客户端请求并返回结果，同时在选举过程中具有投票权
- 观察者仅负责将客户端请求转发给领导者，不参与投票



#### 模式

zab 主要是用于处理崩溃恢复以及主动同步的，因此有两种不同的模式

##### 崩溃恢复模式（选举模式）

当 zk 框架启动时，或是当 leader 节点出现中断、退出等异常情况时进入的。进入崩溃恢复模式后，所有的节点都无法接收新的请求，而是开始选举产生新的 leader。`当新的 leader 产生且集群中有过半的机器与 leader 完成状态同步和数据同步后，zk 才会进入消息广播模式`

##### 消息广播模式（读写模式）

当 zk 进入广播模式后，zk 客户端则可以正常从 zk 集群中读写数据了

- 写操作

  - zab 协议中的写操作通过`类似事务二阶段提交`的方式保证了数据的一致性

  - 特点：写操作只能由 leader 发起，follower 收到写请求会转发给 leader 让其发起

    ​			二阶段提交

- 读操作
  
  - 由于 zab 协议的写操作保证了分布式数据的一致性，因此每个跟随者节点都有最新的数据副本，无论客户端连接哪一个节点都可以直接读取数据

**具体流程：**

写操作可以看做是两个阶段：事务提议阶段和事务提交阶段

- leader 从客户端接收到一个写请求，或是从 follower 接收到一个转发过来的写请求
- leader 生成一个新的事务，并为这个事务生成一个唯一的事务ID
- leader 将这个事务提议(propose)给所有的 follower 节点
- follower 节点将收到的事务请求加入到历史队列中，并发送 ack 返回给 leader
- 当 leader 收到半数以上的 follower 的 ack 消息后， leader 会发送 commit 请求给 follower
- 但 follower 收到 leader 发来的 commit 请求后，会从历史队列中将事务请求 commit



#### Zookeeper 的数据同步类型

- 直接差异化同步(DIFF 同步)
  - 即当前节点的最大事务 id 介于 leader 节点的最小事务 id 和最大事务 id 之间，则会去获取到自己的最大事务id和 leader节点最大事务 id 之间的数据
- 先回滚再差异化同步(TRUNC+DIFF 同步)
  - 若 leader 发现某个 learner 服务器有自己没有的事务记录，则让那个 learner 进行回滚，然后再同步差异化同步

- 仅回滚同步 (TRUNC 同步)
  - 当前节点的最大事务id大于 leader 的最大事务id时，则要回滚到 leader 的最大事务 id 处

- 全量同步 (SNAP 同步)
  - 当前节点的最大事务id小于 leader 的最小事务 id 时会触发全量同步
  - 当前节点是



### 选举策略

#### 节点状态

节点共有四种状态，当集群通过 zab 协议选举时，非观察者节点都会处于 looking 状态，当选举完毕后，节点会自动更改状态为 leading、following

| 状态名    | 状态             | 描述                                                         |
| --------- | ---------------- | ------------------------------------------------------------ |
| looking   | 寻找 leader 状态 | 当服务器处于该状态时，它会认为当前集群中没有 leader，进入 leader 选举状态 |
| leading   | 领导者状态       | 当前服务器的角色是 leader                                    |
| following | 跟随者状态       | 当前服务器的角色是 follower                                  |
| observing | 观察者状态       | 当前服务器的角色是 observe                                   |



#### 选举过程

当服务器启动或 leader 异常断开都会触发重新选举，要发起 leader 选举至少需要两个节点

##### 服务器启动时选举

可以总结为：`自我投票 -> pk投票 -> 统计投票 -> 修改状态`

- **自我投票阶段**

  - 每个节点都会发出一个投票，在自我投票阶段这些节点都会投自己为 leader 服务器，投票内包含自己的 myid 和最大事务id，使用(myid，zxid)来表示。构造投票后会将自己的投票内容发给集群中的其他节点

- **pk 投票阶段**

  - 每个节点都会留有一份投票信息(即自我投票阶段生成的投票)

  - 当节点收到来自其他节点的投票信息时，会将自己保存的投票信息与之 pk，并根据 pk 结果修改自己保存的投票信息

    - 优先以 zxid(最大事务id) 最大的节点作为 leader
    - 若 zxid 相同，则选择 myid 更大的节点作为 leader

    每次 pk 完成后节点都会将自己保存的投票信息发送给集群中的其他节点

- **统计投票阶段**

  - 每次pk投票后服务器都会统计投票信息，当有过半的机器接收到相同的投票信息时，则使这个投票对应的节点成为 leader 节点
  - 由此可以看出，不一定 myid 或 zxid 最大的节点就是 leader 节点

- **修改状态阶段**

  - 在统计投票阶段确定 leader 节点后，集群中的所有节点都会更新自己的状态，并同步 leader 的数据内容，如果被选举为 leader 节点，则状态为 leading，若是 follower 节点，则变更为 following 状态



##### leader 异常时选举

当 leader 节点宕机，整个 zk 集群都会从消费广播模式变为崩溃恢复模式，暂停对外服务，进入新一轮的 leader 选举

- 变更状态
  - leader 挂掉后，所有的节点都会变更状态为 looking，而后开始新一轮选举
- 与启动时的选举流程相同



### Observer 观察者

#### 概念

由于 zk 的写操作需要过半的节点确认，因此随着 follower 节点的增加(业务量要求，即更多的连接数)，会造成写效率的降低，因此引入了`观察者`。

`观察者是一个不参与选举和写操作，只听取选举结果，并与 leader 同步数据，对外提供读写操作(一样是转发给leader)的特殊节点`



#### 特点

- 不参与 leader 选举，只听取投票结果
- 不参与集群中写数据时的 ack 反馈
- 只与 leader 同步数据内容
- 对外提供读写，会将写操作转发给 leader 节点



#### 优点

- 能够在不影响写操作效率的情况下，提高读操作的并发性能
- 不参与投票，因此增加任意台 Observer 也不会降低集群的性能
- Observer 异常不会影响集群可用性，因为不会参与实际的选举和写入



#### 使用

在 zoo.cfg 配置中定义：

```markdown
peerType=observer
```

修改所有节点的配置文件，在后面加上 :observer

```markdown
# 在集群配置中，配置上观察者节点，并在后面加上 :observer
server.1:localhost:2181:3181:observer
```





























